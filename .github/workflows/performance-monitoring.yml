name: Performance Monitoring

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run performance tests daily at 3 AM UTC
    - cron: '0 3 * * *'
  workflow_dispatch:

env:
  NODE_VERSION: '18'

jobs:
  # Frontend Performance Testing
  frontend-performance:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    - name: Install dependencies
      run: npm ci
    - name: Build for production
      run: npm run build
    - name: Run Lighthouse CI
      uses: treosh/lighthouse-ci-action@v10
      with:
        urls: |
          http://localhost:3000
        configPath: .lighthouserc.json
        uploadArtifacts: true
        temporaryPublicStorage: true
    - name: Run Web Vitals monitoring
      run: |
        npm install -g web-vitals
        # Add web vitals monitoring script
        echo "Monitoring web vitals..."
    - name: Bundle size analysis
      run: |
        npx webpack-bundle-analyzer dist/static/js/*.js --mode static --report dist/bundle-analysis.html
    - name: Upload bundle analysis
      uses: actions/upload-artifact@v3
      with:
        name: bundle-analysis
        path: dist/bundle-analysis.html

  # Backend Performance Testing
  backend-performance:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    - name: Setup Rust
      uses: dtolnay/rust-toolchain@stable
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
    - name: Build with release optimizations
      run: cargo build --release
    - name: Run Criterion benchmarks
      run: cargo bench
    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: target/criterion/

  # Memory and CPU Profiling
  profiling:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    - name: Setup Rust
      uses: dtolnay/rust-toolchain@stable
    - name: Install dependencies
      run: npm ci
    - name: Build application
      run: |
        npm run build
        cargo build --release
    - name: Run memory profiling
      run: |
        # Use heaptrack for memory profiling
        sudo apt-get update
        sudo apt-get install -y heaptrack
        heaptrack ./target/release/navlambda-nif --output mem-profile
    - name: Run CPU profiling
      run: |
        # Use perf for CPU profiling
        sudo apt-get install -y linux-tools-common linux-tools-generic
        perf record -F 99 -g -- ./target/release/navlambda-nif --benchmark
        perf script > perf-script.out
    - name: Upload profiling data
      uses: actions/upload-artifact@v3
      with:
        name: profiling-data
        path: |
          mem-profile.*
          perf-script.out

  # Load Testing
  load-testing:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    - name: Setup Rust
      uses: dtolnay/rust-toolchain@stable
    - name: Build application
      run: |
        npm run build
        cargo build --release
    - name: Start application for testing
      run: |
        ./target/release/navlambda-nif &
        APP_PID=$!
        echo "APP_PID=$APP_PID" >> $GITHUB_ENV
        sleep 10
    - name: Run Artillery load tests
      run: |
        npm install -g artillery
        artillery run load-test.yml
    - name: Stop application
      run: |
        kill $APP_PID || true
    - name: Upload load test results
      uses: actions/upload-artifact@v3
      with:
        name: load-test-results
        path: artillery-report.json

  # Database Performance Testing
  database-performance:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    - name: Install dependencies
      run: npm ci
    - name: Run database benchmarks
      run: |
        npm run db:benchmark
    - name: Run query performance tests
      run: |
        npm run test:db-performance
    - name: Upload database performance results
      uses: actions/upload-artifact@v3
      with:
        name: db-performance-results
        path: db-performance-report.json

  # Simulation Performance Testing
  simulation-performance:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    - name: Setup Rust
      uses: dtolnay/rust-toolchain@stable
    - name: Build simulation components
      run: |
        npm run build
        cargo build --release
    - name: Run simulation benchmarks
      run: |
        # Test physics simulation performance
        cargo bench --bench physics_benchmark
        # Test sensor simulation performance
        cargo bench --bench sensor_benchmark
        # Test multi-simulator coordination
        cargo bench --bench multi_sim_benchmark
    - name: Run Oxford dataset processing benchmark
      run: |
        # Test dataset loading and processing performance
        cargo bench --bench dataset_benchmark
    - name: Upload simulation performance results
      uses: actions/upload-artifact@v3
      with:
        name: simulation-performance-results
        path: target/criterion/

  # Performance Regression Detection
  performance-regression:
    runs-on: ubuntu-latest
    needs: [frontend-performance, backend-performance, simulation-performance]
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    - name: Download benchmark results
      uses: actions/download-artifact@v3
      with:
        name: benchmark-results
    - name: Download simulation performance results
      uses: actions/download-artifact@v3
      with:
        name: simulation-performance-results
    - name: Check for performance regressions
      run: |
        # Compare current benchmarks with baseline
        # Fail if performance regresses beyond threshold
        echo "Checking for performance regressions..."

        # Frontend performance check
        if [ -f "lighthouse-results.json" ]; then
          PERFORMANCE_SCORE=$(jq '.categories.performance.score * 100' lighthouse-results.json)
          if (( $(echo "$PERFORMANCE_SCORE < 90" | bc -l) )); then
            echo "❌ Performance score too low: $PERFORMANCE_SCORE"
            exit 1
          fi
        fi

        # Bundle size check
        if [ -f "bundle-analysis.html" ]; then
          BUNDLE_SIZE=$(grep -oP 'Total bundle size: \K[0-9.]+' bundle-analysis.html || echo "0")
          if (( $(echo "$BUNDLE_SIZE > 5000000" | bc -l) )); then
            echo "❌ Bundle size too large: $BUNDLE_SIZE bytes"
            exit 1
          fi
        fi

        echo "✅ No performance regressions detected"
    - name: Update performance baseline
      if: github.ref == 'refs/heads/main'
      run: |
        # Store current performance metrics as new baseline
        echo "Updating performance baseline..."

  # Performance Monitoring Dashboard
  performance-dashboard:
    runs-on: ubuntu-latest
    needs: [frontend-performance, backend-performance, profiling, load-testing, database-performance, simulation-performance, performance-regression]
    if: always()
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    - name: Download all performance artifacts
      uses: actions/download-artifact@v3
    - name: Generate performance report
      run: |
        echo "# Performance Monitoring Report" > performance-report.md
        echo "" >> performance-report.md
        echo "## Test Results" >> performance-report.md
        echo "- Frontend Performance: ${{ needs.frontend-performance.result }}" >> performance-report.md
        echo "- Backend Performance: ${{ needs.backend-performance.result }}" >> performance-report.md
        echo "- Profiling: ${{ needs.profiling.result }}" >> performance-report.md
        echo "- Load Testing: ${{ needs.load-testing.result }}" >> performance-report.md
        echo "- Database Performance: ${{ needs.database-performance.result }}" >> performance-report.md
        echo "- Simulation Performance: ${{ needs.simulation-performance.result }}" >> performance-report.md
        echo "- Regression Check: ${{ needs.performance-regression.result }}" >> performance-report.md
        echo "" >> performance-report.md
        echo "## Timestamp: $(date)" >> performance-report.md
        echo "" >> performance-report.md

        # Add performance metrics summary
        echo "## Performance Metrics Summary" >> performance-report.md
        echo "" >> performance-report.md

        # Frontend metrics
        if [ -f "lighthouse-results.json" ]; then
          PERF_SCORE=$(jq '.categories.performance.score * 100' lighthouse-results.json 2>/dev/null || echo "N/A")
          echo "- Lighthouse Performance Score: $PERF_SCORE/100" >> performance-report.md
        fi

        # Bundle size
        if [ -f "bundle-analysis.html" ]; then
          BUNDLE_SIZE=$(grep -oP 'Total bundle size: \K[0-9.]+' bundle-analysis.html 2>/dev/null || echo "N/A")
          echo "- Bundle Size: $BUNDLE_SIZE bytes" >> performance-report.md
        fi

        echo "" >> performance-report.md
        echo "## Recommendations" >> performance-report.md
        echo "- Monitor bundle size growth" >> performance-report.md
        echo "- Track Lighthouse performance scores" >> performance-report.md
        echo "- Review benchmark regressions" >> performance-report.md
    - name: Upload performance report
      uses: actions/upload-artifact@v3
      with:
        name: performance-report
        path: performance-report.md
    - name: Comment on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('performance-report.md', 'utf8');

          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: report
          });

on:
  schedule:
    - cron: '0 */6 * * *'  # Run every 6 hours
  workflow_dispatch:
  workflow_call:

env:
  NODE_VERSION: '18.x'
  PERFORMANCE_THRESHOLD: 80

jobs:
  performance-baseline:
    name: Establish Performance Baseline
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build

      - name: Run performance baseline tests
        run: |
          npm run test:performance:baseline
          npm run performance:collect-baseline

      - name: Upload baseline data
        uses: actions/upload-artifact@v3
        with:
          name: performance-baseline
          path: performance/baseline.json
          retention-days: 90

  performance-monitoring:
    name: Performance Monitoring
    runs-on: ubuntu-latest
    needs: performance-baseline
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Download baseline data
        uses: actions/download-artifact@v3
        with:
          name: performance-baseline
          path: performance/

      - name: Run performance monitoring
        run: |
          npm run performance:monitor
          npm run performance:analyze

      - name: Generate performance report
        run: npm run performance:report

      - name: Upload performance report
        uses: actions/upload-artifact@v3
        with:
          name: performance-report-${{ github.run_number }}
          path: performance/report/
          retention-days: 30

      - name: Check performance regression
        id: regression-check
        run: |
          PERFORMANCE_SCORE=$(cat performance/report/score.txt)
          echo "PERFORMANCE_SCORE=$PERFORMANCE_SCORE" >> $GITHUB_OUTPUT
          
          if [ "$PERFORMANCE_SCORE" -lt "${{ env.PERFORMANCE_THRESHOLD }}" ]; then
            echo "Performance regression detected! Score: $PERFORMANCE_SCORE"
            exit 1
          fi

  load-testing:
    name: Load Testing
    runs-on: ubuntu-latest
    needs: performance-baseline
    strategy:
      matrix:
        scenario: [light, moderate, heavy, extreme]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build

      - name: Start application for load testing
        run: |
          npm start &
          sleep 10
          npx wait-on http://localhost:3000

      - name: Run load tests - ${{ matrix.scenario }}
        run: |
          npm run test:load:${{ matrix.scenario }}

      - name: Analyze load test results
        run: |
          npm run analyze:load:${{ matrix.scenario }}

      - name: Upload load test results
        uses: actions/upload-artifact@v3
        with:
          name: load-test-${{ matrix.scenario }}-${{ github.run_number }}
          path: performance/load-tests/${{ matrix.scenario }}/
          retention-days: 30

  memory-leak-detection:
    name: Memory Leak Detection
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build

      - name: Run memory leak tests
        run: |
          npm run test:memory-leak
          npm run analyze:memory-leak

      - name: Generate memory leak report
        run: npm run report:memory-leak

      - name: Upload memory leak report
        uses: actions/upload-artifact@v3
        with:
          name: memory-leak-report-${{ github.run_number }}
          path: performance/memory-leak/
          retention-days: 30

  bundle-analysis:
    name: Bundle Size Analysis
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Analyze bundle size
        run: |
          npm run analyze:bundle
          npm run compare:bundle

      - name: Check bundle size limits
        run: |
          BUNDLE_SIZE=$(cat performance/bundle/size.txt)
          LIMIT=5000000  # 5MB limit
          
          if [ "$BUNDLE_SIZE" -gt "$LIMIT" ]; then
            echo "Bundle size exceeded limit: $BUNDLE_SIZE > $LIMIT"
            exit 1
          fi

      - name: Upload bundle analysis
        uses: actions/upload-artifact@v3
        with:
          name: bundle-analysis-${{ github.run_number }}
          path: performance/bundle/
          retention-days: 30

  lighthouse-audit:
    name: Lighthouse Audit
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build

      - name: Start application
        run: |
          npm start &
          sleep 10
          npx wait-on http://localhost:3000

      - name: Run Lighthouse audit
        run: |
          npm run lighthouse:audit
          npm run lighthouse:report

      - name: Upload Lighthouse report
        uses: actions/upload-artifact@v3
        with:
          name: lighthouse-report-${{ github.run_number }}
          path: performance/lighthouse/
          retention-days: 30

      - name: Check Lighthouse scores
        run: |
          PERFORMANCE_SCORE=$(cat performance/lighthouse/performance-score.txt)
          ACCESSIBILITY_SCORE=$(cat performance/lighthouse/accessibility-score.txt)
          BEST_PRACTICES_SCORE=$(cat performance/lighthouse/best-practices-score.txt)
          SEO_SCORE=$(cat performance/lighthouse/seo-score.txt)
          
          echo "Performance: $PERFORMANCE_SCORE"
          echo "Accessibility: $ACCESSIBILITY_SCORE"
          echo "Best Practices: $BEST_PRACTICES_SCORE"
          echo "SEO: $SEO_SCORE"
          
          # Fail if any score is below 80
          if [ "$PERFORMANCE_SCORE" -lt "80" ] || \
             [ "$ACCESSIBILITY_SCORE" -lt "80" ] || \
             [ "$BEST_PRACTICES_SCORE" -lt "80" ] || \
             [ "$SEO_SCORE" -lt "80" ]; then
            echo "Lighthouse audit failed - scores too low"
            exit 1
          fi

  performance-comparison:
    name: Performance Comparison
    runs-on: ubuntu-latest
    needs: [performance-monitoring, load-testing, lighthouse-audit]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all performance artifacts
        uses: actions/download-artifact@v3
        with:
          path: performance-artifacts/

      - name: Compare performance with baseline
        run: |
          npm run performance:compare
          npm run performance:trend-analysis

      - name: Generate performance summary
        run: |
          npm run performance:summary
          npm run performance:recommendations

      - name: Upload performance comparison
        uses: actions/upload-artifact@v3
        with:
          name: performance-comparison-${{ github.run_number }}
          path: performance/comparison/
          retention-days: 90

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('performance/comparison/summary.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Performance Report\n\n${summary}`
            });

  performance-alerting:
    name: Performance Alerting
    runs-on: ubuntu-latest
    needs: [performance-comparison]
    if: failure()
    steps:
      - name: Send Slack notification
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          channel: '#performance-alerts'
          webhook_url: ${{ secrets.SLACK_WEBHOOK_PERFORMANCE }}
          fields: repo,message,commit,author,workflow
          text: 'Performance regression detected in NAVΛ Studio!'

      - name: Create GitHub issue
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('performance/comparison/summary.md', 'utf8');
            
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Performance Regression - ${new Date().toISOString()}`,
              body: `## Performance Regression Detected\n\n${summary}\n\n## Action Required\n- [ ] Investigate root cause\n- [ ] Implement performance improvements\n- [ ] Re-run performance tests\n- [ ] Verify improvements`,
              labels: ['performance', 'regression', 'high-priority']
            });

  cleanup:
    name: Cleanup Old Performance Data
    runs-on: ubuntu-latest
    needs: [performance-comparison]
    if: always()
    steps:
      - name: Delete old performance artifacts
        uses: actions/delete-artifact@v2
        with:
          name: performance-report-*
          min-versions-to-keep: 10

      - name: Cleanup old baseline data
        run: |
          # Keep only last 30 days of baseline data
          find performance/baselines/ -name "*.json" -mtime +30 -delete || true